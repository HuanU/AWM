{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authors: Eli Gumble, Peter Brommer, Harry Brown\n",
    "#Initialisation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from scipy.integrate import simps\n",
    "from scipy import signal as sg\n",
    "from scipy.interpolate import RectBivariateSpline as ReBiSpline \n",
    "from numpy import ma\n",
    "#from matplotlib import colors, ticker, cm\n",
    "#from random import choice\n",
    "import scipy.ndimage.filters as filters\n",
    "import scipy.ndimage.morphology as morphology\n",
    "import timeit\n",
    "import math\n",
    "#from PIL import Image\n",
    "\n",
    "import matplotlib.image as image\n",
    "import itertools\n",
    "from scipy import ndimage\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import multiprocessedfunctions as mpf\n",
    "import multiprocessedfunctions2 as mpf2\n",
    "import multiprocessedfunctions6 as mpf6\n",
    "import multiprocessedfunctions7 as mpf7\n",
    "import multiprocessedfunctions8 as mpf8\n",
    "import multiprocessedfunctions3 as mpf3\n",
    "import multiprocessedfunctions3_2 as mpf3_2\n",
    "from globalparameters import * # parameters below have been relocated into globalparameters.py\n",
    "#from scipy import stats\n",
    "#import statistics\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read grids from image\n",
    "\n",
    "im = image.imread(\"empty200x200grass.bmp\")\n",
    "Base = np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                        [[r,   g,   r2,  g2], ...]     description\n",
    "landcoverlist = np.array([[22,  95,  0,   0],           # water\n",
    "                          [209, 209, 150, 150],         # bare floor\n",
    "                          [139, 139, 175, 175],         # artificial surface\n",
    "                          [77,  77,  0,   0],           # railway\n",
    "                          [221, 5,   0,   0],           # building\n",
    "                          [255, 84,  0,   0],           # greenhouse\n",
    "                          [255, 255, 0,   200],         # herbaceous cover in rotation throughout year\n",
    "                          [234, 255, 70,  200],         # herbaceous cover (grass)\n",
    "                          [40,  202, 40,  200],         # tall hardwood > 3m\n",
    "                          [185, 233, 30,  200],         # short hardwood < 3m\n",
    "                          [1,   47,  65,  200],         # tall softwood > 3m\n",
    "                         #[0,   0,   0,   0],           # short softwood < 3m\n",
    "                          [43,  80,  0,   0]])          # boundary\n",
    "\n",
    "for k in range (len(landcoverlist)):\n",
    "    for i in range(len(Base)):             #vertical pixels\n",
    "        for j in range(len(Base[0])):      #horizontal pixels\n",
    "            if Base[i][j][0] == landcoverlist[k,0] and Base[i][j][1] == landcoverlist[k,1]:\n",
    "                Base[i][j] = [landcoverlist[k,2],landcoverlist[k,3],0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base[:,:,2] = 0 #set all pixel B values to 0\n",
    "\n",
    "Base[:,:,3] = 255 #set all of the 4th rgb element to 255 because things might break otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define internal quantities and variables\n",
    "scale = 1./2. #m per pixel\n",
    "Nx = Base[:,0,0].size #N appears to be resolution\n",
    "Ny = Base[0,:,0].size\n",
    "xmin=-scale*0.5*(Nx-1)\n",
    "xmax=scale*0.5*(Nx-1)\n",
    "ymin=-scale*0.5*(Ny-1)\n",
    "ymax=scale*0.5*(Ny-1)\n",
    "x = np.linspace(xmin, xmax, Nx) # This is defining the axes and full space\n",
    "y = np.linspace(ymin, ymax, Ny)\n",
    "Y, X= np.meshgrid(y, x)\n",
    "TrailPotential = np.zeros((Nx,Ny))\n",
    "DestinationPotential=np.zeros((Nx,Ny))\n",
    "Weight=np.zeros((Nx,Ny))  # Create gradient to sit on Nx, Ny\n",
    "intens=np.zeros((Nx,Ny))\n",
    "q_alpha=np.zeros((Nx,Ny))\n",
    "expdist=np.zeros((2*Nx-1,2*Ny-1))\n",
    "dest=np.zeros((2))\n",
    "start=np.zeros((2))\n",
    "grad=np.zeros((2,Nx,Ny))\n",
    "vel=np.asarray([0.,0.])\n",
    "pos=np.asarray([0.,0.])\n",
    "stalledpos = [] # empty container for stalled positions of walkers\n",
    "stalledposrounded = []\n",
    "\n",
    "intens[:]=0.\n",
    "isigma=0.2 # functions as 'smoothing intensity' of trail potentials, value < 0.5 leads to more smoothing, can cause more path merging and fewer straight lines\n",
    "#t._track=25. # Track decay time - after 50 walkers ignore a trail, it decays by 1/e\n",
    "wlkr_range = 10000\n",
    "#print(route)\n",
    "'''\n",
    "#parameters\n",
    "dt=0.1  # dt per time step, continuous markings every dt metres\n",
    "dvel=1. # desired walker velocity in m/s\n",
    "tau=5.\n",
    "isigma=0.5 # trail potential\n",
    "trailpotweight = 0.004 # weighting of trail potential over destination potential, started as 0.003, increasing this increases number of stalls\n",
    "storedtrailpotweight = trailpotweight\n",
    "conv_thresh=10.e-4\n",
    "precision=1.**2 #distance to target.\n",
    "eps=0.025 #random motion contribution, same for all\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up map\n",
    "#Create blank arrays for map \n",
    "z = np.zeros((Nx,Ny))\n",
    "g_max=np.zeros((Nx,Ny))\n",
    "g_nat=np.zeros((Nx,Ny))\n",
    "\n",
    "g_nat=np.maximum(np.ones_like(g_nat),np.float64(Base[:,:,0]))\n",
    "g_max=np.maximum(np.ones_like(g_max),np.float64(Base[:,:,1]))\n",
    "z=g_nat\n",
    "\n",
    "track_labels=Base[:,:,2]\n",
    "\n",
    "numpoints=np.max(track_labels)\n",
    "\n",
    "point=np.zeros((numpoints,2))\n",
    "\n",
    "for i in range(0,Nx):\n",
    "    for j in range(0,Ny):\n",
    "        if (track_labels[i,j]>0):\n",
    "            point[track_labels[i,j]-1]=np.array([i,j])\n",
    "print (point)\n",
    "\n",
    "# Trails (start and end point) For current Map, coordinates in metres, centre of image = (0,0)\n",
    "\n",
    "# single possible path\n",
    "# route=np.array([[24.,-9.75],[-24.,9.75]]),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# big field with tennis court parking lot and hospital, near rue cottrel\n",
    "ptA = [-40.,-240.]      # tennis court near middle\n",
    "ptB = [-250.,-200.]     # tennis court near skatepark\n",
    "#ptC = [-350., 25.]     # parking lot entrance >>>>>>>>>>>>> removed because its very close to ptD, won't give interesting information, not worth computational work\n",
    "ptD = [-350., 80.]      # parking lot bus stop\n",
    "ptE = [-70., 230.]      # east road pedestrian entrance\n",
    "ptF = [200., 200.]      # hospital bus stop\n",
    "ptG = [250., 100.]      # hospital side path\n",
    "ptH = [350., -100.]     # dirt car park\n",
    "ptI = [210., -140.]     # west side entrance\n",
    "\n",
    "#listofdestinations = [ptA,ptB,ptD,ptE,ptF,ptG,ptH,ptI,ptA,ptB,ptD,ptE,ptF,ptG,ptH,ptI] # list is repeated so that the combinations function below generates not only AB but BA\n",
    "listofdestinations = [[0,25],[-10,-25],[10,-25],[0,25],[-10,-25],[10,-25],] #steiner points 200x200\n",
    "#listofdestinations = [[0,10],[-5,-10],[5,-10],[0,10],[-5,-10],[5,-10]] #steiner points 200x200 (small scale)\n",
    "\n",
    "##listofdestinations = [[150,25],[-165,45]] # fieldwithcrops\n",
    "#listofdestinations = [[-165,45],[150,25],[0,-85],[-165,45],[150,25],[0,-85]] # fieldwithcrops\n",
    "# listofdestinations = [[0,-85],[-165,45],[150,25],[0,-85],[-165,45],[150,25]]\n",
    "#listofdestinations = [[0,-85],[150,25],[-165,45],[0,-85],[150,25],[-165,45]]\n",
    "\n",
    "#listofdestinations = [[40,20],[-40,20],[40,-20],[-40,-20],[40,20],[-40,20],[40,-20],[-40,-20]] # criss cross thing\n",
    "\n",
    "#listofdestinations = [[-375, -160], [-330, -50], [210, 110], [300, 20], [340, -80], [390, -150]] #madeleine\n",
    "#listofdestinations = [[-25,-25],[25,25]]\n",
    "route = []\n",
    "\n",
    "#       should probably turn all of this into a function\n",
    "\n",
    "# generate route combinations\n",
    "for i in itertools.combinations(listofdestinations, 2):\n",
    "    route.append(i)\n",
    "\n",
    "# remove duplicate routes https://stackoverflow.com/questions/2213923/removing-duplicates-from-a-list-of-lists\n",
    "routetemp = []\n",
    "for i in route:\n",
    "    if i not in routetemp:\n",
    "        routetemp.append(i)\n",
    "route = routetemp\n",
    "\n",
    "# delete AA, BB, CC routes\n",
    "zzzzz = -1\n",
    "for row in route:\n",
    "    zzzzz+=1\n",
    "    if row[0] == row[1]:\n",
    "        route.pop(zzzzz)\n",
    "\n",
    "routearray = np.empty((len(route),2,2))\n",
    "\n",
    "# convert list of lists to 3d array\n",
    "for k in range(len(route)):\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            routearray[k][i][j] = route[k][i][j]\n",
    "\n",
    "route = routearray # convert routearray back to variable name understood by code\n",
    "#route = [[[0,100],[-25,0]],[[0,100],[25,0]]]\n",
    "\n",
    "#route = np.array([[[-30, 20],[0,40]],[[-30,-20],[0,-20]],[[0,20],[-30, 20]],[[0,-20],[-30,-20]]])\n",
    "\n",
    "t_track=float(len(route)) # Track decay time - after 50 walkers ignore a trail, it decays by 1/e\n",
    "#t_track = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in listofdestinations\n",
    "#    route[i,0:len(listofdestinations)] = listofdestinations[i]\n",
    "\n",
    "# small field by apartment with 4 entrances \n",
    "#posA = [-5., -17.]\n",
    "#posB = [-25., -17.]\n",
    "#posC = [-25., 8.]\n",
    "#posD = [40., 10.]\n",
    "\n",
    "# acceptable routes = A/B to C, A/C to D and vice versa, 8 total routes\n",
    "#route=np.array([[posA,posC],\n",
    "#                 [posB,posC],\n",
    "#                 [posC,posA],\n",
    "#                 [posC,posD],\n",
    "#                 [posA,posC],\n",
    "#                 [posC,posD],\n",
    "#                 [posD,posA],\n",
    "#                 [posD,posC],\n",
    "#                 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup weight matrix, here trapezoid rule.\n",
    "Weight[:,:]=1\n",
    "Weight[1:-1,:]=2\n",
    "Weight[:,1:-1]=2\n",
    "Weight[1:-1,1:-1]=4\n",
    "Weight*=0.25*((x[-1]-x[0])/(Nx-1))*((y[-1]-y[0])/(Ny-1))\n",
    "#0.25*((x[-1]-x[0])/(N-1))*((y[-1]-y[0])/(N-1))\n",
    "#np.exp(-np.sqrt((x[:,None]-x[N/2])**2+(y[None,:]-y[N/2])**2))*z[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup distance matrix\n",
    "for xi in range(1,Nx+1):\n",
    "    for yi in range(1,Ny+1):\n",
    "        \n",
    "        expdist[xi-1,yi-1]=np.exp(-isigma*np.sqrt((x[Nx-xi]-xmin)**2+(y[Ny-yi]-ymin)**2))\n",
    "        expdist[-xi,-yi]  = expdist[xi-1,yi-1]\n",
    "        expdist[-xi,yi-1] = expdist[xi-1,yi-1]\n",
    "        expdist[xi-1,-yi] = expdist[xi-1,yi-1]\n",
    "        \n",
    "# find index range > conv_thresh\n",
    "subexpdist=expdist[(expdist>conv_thresh).any(1)]\n",
    "subexpdist=subexpdist[:, np.any(subexpdist>conv_thresh, axis=0)]\n",
    "\n",
    "#subexpdist=subexpdist[:,np.any(subexpdist>conv_thresh, axis=0)]\n",
    "#expdist[subexpdist]=0.\n",
    "subexpdist.shape\n",
    "#expdist\n",
    "#subexpdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tr_new():\n",
    "    TrailPotential[:,:]=sg.convolve2d(z[:,:]*Weight[:,:],subexpdist[:,:],mode=\"same\")  # 2D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TrailPotential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tr_gauss():\n",
    "    TrailPotential[:,:]=ndimage.gaussian_filter(z[:,:], 1, 0) #,TrailPotential,mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate z, trapezoid rule eq 20\n",
    "def calc_tr():\n",
    "    global xi,yi,tr,expdist,z,wght,Nx,Ny\n",
    "    for xi in range(0,Nx): \n",
    "        for yi in range(0,Ny):\n",
    "            tr[xi,yi]=np.sum(expdist[Nx-1-xi:2*Nx-1-xi,Ny-1-yi:2*Ny-1-yi]*z[:,:]*wght[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit(calc_tr_new,number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a Plot to show the smoothing of the supplied map to represent the respective potentials of the ground, the larger\n",
    "# the potentials, the more attractive the ground is to the walker\n",
    "\n",
    "cs = plt.contourf(X, Y, TrailPotential, levels=np.linspace(TrailPotential.min(),TrailPotential.max(),1000),cmap='PuBu_r')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.show()\n",
    "#plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up walker\n",
    "def set_up_walker(route_id):\n",
    "    global vel, pos, track, dest, start, route\n",
    "    #start\n",
    "    dispersion = 5 # length away from start point walkers are allowed to spawn, measured in m\n",
    "\n",
    "    start = np.array(route[route_id, 0, :]) # commented for simplicity\n",
    "    start[0] += np.random.randint(-dispersion, dispersion+1) # adds dispersion to x\n",
    "    start[1] += np.random.randint(-dispersion, dispersion+1) # adds dispersion to y\n",
    "    # start = np.array([24.,-9.75])  # temporary one route\n",
    "    # dest = np.array([-24.,9.75])  # temporary one route\n",
    "    # dest=(random.choice(ends))\n",
    "    dest = np.array(route[route_id, 1, :]) # commented for simplicity\n",
    "    dest[0] += np.random.randint(-dispersion, dispersion+1)\n",
    "    dest[1] += np.random.randint(-dispersion, dispersion+1)\n",
    "    vel = np.array([0., 0.])\n",
    "    pos = np.array(start)\n",
    "    #print (pos)\n",
    "    track = np.zeros((wlkr_range, 2))\n",
    "    #track[0,:]=pos[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate gradients eq 19\n",
    "#Trail gradient\n",
    "def setup_potentials():\n",
    "    global grad,desdirx,desdiry,dest,trailpotweight\n",
    "    grad=np.zeros((2,Nx,Ny))\n",
    "    grad=trailpotweight*np.array(np.gradient(TrailPotential))\n",
    "    #grad=0.002*np.array(np.gradient(TrailPotential)) ORIGINAL\n",
    "    \n",
    "    #print (dest)\n",
    "    #Destination potential\n",
    "    DestinationPotential=-np.sqrt((dest[0]-x[:,None])**2+(dest[1]-y[None,:])**2)\n",
    "    #Combine gradients\n",
    "    grad+=np.array(np.gradient(DestinationPotential)[:])\n",
    "    #Normalise\n",
    "    #grad[:,:,:]/=(np.sqrt(grad[0,:,:]**2+grad[1,:,:]**2))\n",
    "    desdirx=ReBiSpline(x,y,grad[0,:,:],s=2) # gradeint plus magnitude, Spline approximation over a rectangular mesh\n",
    "    desdiry=ReBiSpline(x,y,grad[1,:,:],s=2) \n",
    "    #plot()\n",
    "    #print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the direction\n",
    "# scgrad=np.arctan2(grad[1],grad[0])\n",
    "# levels = np.linspace(-np.pi, np.pi, 360)\n",
    "# cs = plt.contourf(X, Y,scgrad, levels=levels,cmap='hsv')\n",
    "\n",
    "# cbar = plt.colorbar()\n",
    "# # ERROR # plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1])\n",
    "# #plt.scatter(start, dest)\n",
    "# print(start)\n",
    "# print(dest)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function rounds a point, and checks if it is already in the list of rounded points\n",
    "# If its already in the list it, it increases the count value for that point by 1\n",
    "# If its not in the list, it adds it to the list with a count of 1\n",
    "\n",
    "def stalledposregioncounter(newpos,stalledposrounded2):\n",
    "    nearest = 5\n",
    "    newposxrounded = round(newpos[0]/nearest)*nearest # round x\n",
    "    newposyrounded = round(newpos[1]/nearest)*nearest # round y\n",
    "\n",
    "    newposrounded = {\"x\":newposxrounded,\"y\":newposyrounded,\"count\":1}\n",
    "    \n",
    "    for i in stalledposrounded2:\n",
    "        if i[\"x\"] == newposrounded[\"x\"] and i[\"y\"] == newposrounded[\"y\"]:\n",
    "            i[\"count\"]+=1\n",
    "            return stalledposrounded2\n",
    "    stalledposrounded2.append(newposrounded)\n",
    "    return stalledposrounded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_path():\n",
    "    global pos,vel,intens,track,dest,dvel,tau,stalledpos,stalledposrounded,trailpotweight,storedtrailpotweight\n",
    "    \n",
    "    i=0\n",
    "    hist=10\n",
    "    samp=10\n",
    "    avpos=np.zeros((2,hist))\n",
    "    internalclock = 0 # not measured in seconds, probably measured in 'dt's\n",
    "    stallcounter = 0\n",
    "    trailpotweight = 0.004 # weighting of trail potential over destination potential, started as 0.003, increasing this increases number of stalls\n",
    "    storedtrailpotweight = trailpotweight\n",
    "\n",
    "    # https://www.programiz.com/python-programming/datetime/current-time\n",
    "    #now = datetime.now()\n",
    "    #current_time = now.strftime(\"%H:%M:%S\")\n",
    "    #print(\"Calc path entered, time =\", current_time)\n",
    "\n",
    "    #Setup While loop to run until either the walker reaches the destination or the walker has passed 'wlkr_range' number of movement cycles to \n",
    "    #attempt to get there\n",
    "    while (np.dot(pos-dest,pos-dest)>precision and i<wlkr_range):\n",
    "    #set the postiion of the walker on its first then subsequent cycles\n",
    "        \n",
    "        #conditional logic saying to update the average position of the walker every 10 iterations\n",
    "        #if (i%samp==0): avpos[:,(i%hist)//samp]=pos[:] #ORIGINAL\n",
    "        if (i%samp==0): avpos[:,(i%(hist*samp))//samp]=pos[:]\n",
    "            \n",
    "        #print((i%hist)//samp)\n",
    "        #print(avpos)\n",
    "        \n",
    "        gradmagnitude=max(0.0001,np.sqrt(desdirx(pos[0],pos[1])**2+desdiry(pos[0],pos[1])**2))\n",
    "        xi=np.array(np.random.normal(0,1,2))\n",
    "        # Equation 6 in Helbing, differential in position, eliminised velocity decay components\n",
    "        # gradmagnitude makes sure it is normalised, desdir not normalised\n",
    "        pos[0]+= dt *(dvel * desdirx(pos[0],pos[1])/gradmagnitude +np.sqrt(2.*eps/tau)*xi[0])  # x-position vector component \n",
    "        pos[1]+= dt *(dvel * desdiry(pos[0],pos[1])/gradmagnitude +np.sqrt(2.*eps/tau)*xi[1])  # y-position vector component\n",
    "        \n",
    "        internalclock+=1\n",
    "        if internalclock == 250 and trailpotweight != storedtrailpotweight:\n",
    "                trailpotweight = storedtrailpotweight\n",
    "                #print(trailpotweight)\n",
    "                setup_potentials() # recalculate potentials\n",
    "        \n",
    "#        posGrad = math.degree(math.atan(pos[0]/pos[1]) # future position\n",
    "        curDir = math.atan(desdiry(pos[0],pos[1])/desdirx(pos[0],pos[1]))\n",
    "#         print(posGrad)\n",
    "        # print(curDir)\n",
    "        # pos+=dt*vel\n",
    "        \n",
    "        #vel[0]+=-1/tau*vel[0] + (dvel/tau)*desdirx(pos[0],pos[1])/gradmagnitude+np.sqrt(2.*eps/tau)*xi[0]   # Eqiation 5 in Helbing, differential in velocity\n",
    "        #vel[1]+=-1/tau*vel[1] + (dvel/tau)*desdiry(pos[0],pos[1])/gradmagnitude+np.sqrt(2.*eps/tau)*xi[1]\n",
    "        \n",
    "        #Set the current position of the walker into the trakc array for the current iteration\n",
    "        track[i,:]=pos[:]\n",
    "\n",
    "#        if math.isnan(pos[1])==1: \n",
    "#                print (\"NaN error \",pos,vel, dest)\n",
    "#                break\n",
    "\n",
    "        intens[int((pos[0]-xmin)*(Nx-1)/(xmax-xmin)),int((pos[1]-ymin)*(Ny-1)/(ymax-ymin))]+=1.\n",
    "        i+=1\n",
    "        if (i%(hist*samp)==0):\n",
    "            meanpos=np.mean(avpos,axis=1)\n",
    "            if (np.dot(pos-meanpos,pos-meanpos)<precision): \n",
    "                #print (\"Stalled progress \",pos,meanpos,vel, dest)\n",
    "                #stalledpos.append(meanpos) # store positions where walkers are stalled\n",
    "                #stalledposrounded = stalledposregioncounter(meanpos, stalledposrounded) # store ROUNDED positions of walker stalls and count occurence in rounded position\n",
    "                trailpotweight = 0.002 # reduce tpotweight to favour destination more\n",
    "                #print(trailpotweight)\n",
    "                setup_potentials() # recalculate the trail potentials with lower weight\n",
    "                internalclock = 0 # reset clock\n",
    "                stallcounter+=1 # take notice of the fact that there was a stall\n",
    "                #break\n",
    "        if stallcounter == 3: # 3 represents the number of stalls before stopping the walker, this will happen with hard obstacles like buildings and water\n",
    "                print (\"Stalled progress \",pos,meanpos, dest)\n",
    "                stalledpos.append(meanpos) # store positions where walkers are stalled\n",
    "                stalledposrounded = stalledposregioncounter(meanpos, stalledposrounded) # store ROUNDED positions of walker stalls and count occurence in rounded position\n",
    "                break\n",
    "    if (i==wlkr_range): print (\"Missed goal \",dest,pos)           \n",
    "    return i    \n",
    "#stopping condition   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q_alpha (strength of markings) eq 15\n",
    "def update_ground_old():\n",
    "    global q_alpha,intens,z,g_max,t_track,g_nat\n",
    "    q_alpha=intens*(1.-z/g_max)\n",
    "    # Time evolution of ground potential\n",
    "    #zdiff=(1./t_track)*(g_nat-z)+q_alpha\n",
    "    z+=(1./t_track)*(g_nat-z)+q_alpha\n",
    "    #cs = plt.contourf(X, Y, zdiff, cmap=cm.PuBu_r)\n",
    "    #cbar = plt.colorbar()\n",
    "    #plt.show\n",
    "    #z[140:160,45:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q_alpha (strength of markings) eq 15\n",
    "def update_ground():\n",
    "    global q_alpha,intens,z,g_max,t_track,g_nat,Nx,Ny\n",
    "\n",
    "    for zj in range(Nx):\n",
    "        for zi in range(Ny):\n",
    "            if z[zj][zi] > g_max[zj][zi]: z[zj][zi] = g_max[zj][zi]\n",
    "            if z[zj][zi] < g_nat[zj][zi]: z[zj][zi] = g_nat[zj][zi]\n",
    "\n",
    "    q_alpha=intens*(1.-z/g_max)\n",
    "    # Time evolution of ground potential\n",
    "    #zdiff=(1./t_track)*(g_nat-z)+q_alpha\n",
    "    z+=(1./t_track)*(g_nat-z)+q_alpha\n",
    "\n",
    "    for zj in range(Nx):\n",
    "        for zi in range(Ny):\n",
    "            if z[zj][zi] > g_max[zj][zi]: z[zj][zi] = g_max[zj][zi]\n",
    "            if z[zj][zi] < g_nat[zj][zi]: z[zj][zi] = g_nat[zj][zi]\n",
    "\n",
    "    #cs = plt.contourf(X, Y, zdiff, cmap=cm.PuBu_r)\n",
    "    #cbar = plt.colorbar()\n",
    "    #plt.show\n",
    "    #z[140:160,45:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path():\n",
    "    plt.contourf(X, Y, z, levels=np.linspace(0,z.max(),1000),cmap='PuBu_r')\n",
    "    plt.colorbar()\n",
    "    #plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1],1,np.array([[0,1,0]]))\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_line():\n",
    "    plt.contourf(X, Y, z, levels=np.linspace(0,z.max(),1000),cmap='PuBu_r')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1],1,np.array([[0,1,0]]))\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_intens():\n",
    "    plt.contourf(X, Y, intens, levels=np.linspace(0,z.max(),1000),cmap='PuBu_r')\n",
    "    plt.colorbar()\n",
    "    #plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1],1,np.array([[0,1,0]]))\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path2():\n",
    "    global stalledpos\n",
    "    markercolour = np.array([[1,0,0]])\n",
    "\n",
    "    plt.contourf(X, Y, z, levels=np.linspace(z.min(),z.max(),1000),cmap='PuBu_r')\n",
    "    \n",
    "    stalledposarray = np.array(stalledpos)\n",
    "    plt.scatter(stalledposarray[0:-1,0],stalledposarray[0:-1,1],1.,markercolour)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path3():\n",
    "    global stalledposrounded\n",
    "    stalledposrounded3 = []\n",
    "\n",
    "    markercolour = np.array([[1,0,0]])\n",
    "    \n",
    "    plt.contourf(X, Y, z, levels=np.linspace(z.min(),z.max(),1000),cmap='PuBu_r')\n",
    "    \n",
    "    for i in stalledposrounded:\n",
    "        stalledposrounded3.append([i[\"x\"],i[\"y\"]])\n",
    "\n",
    "    stalledposarray2 = np.array(stalledposrounded3)\n",
    "    plt.scatter(stalledposarray2[0:-1,0],stalledposarray2[0:-1,1],1.,markercolour)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_local_maxima(arr):\n",
    "    # https://stackoverflow.com/questions/3684484/peak-detection-in-a-2d-array/3689710#3689710\n",
    "    \"\"\"\n",
    "    Takes an array and detects the troughs using the local maximum filter.\n",
    "    Returns a boolean mask of the troughs (i.e. 1 when\n",
    "    the pixel's value is the neighborhood maximum, 0 otherwise)\n",
    "    \"\"\"\n",
    "    # define an connected neighborhood\n",
    "    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.morphology.html#generate_binary_structure\n",
    "    neighborhood = morphology.generate_binary_structure(len(arr.shape),2)\n",
    "    # apply the local minimum filter; all locations of minimum value \n",
    "    # in their neighborhood are set to 1\n",
    "    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.filters.html#minimum_filter\n",
    "    local_max = (filters.maximum_filter(arr, footprint=neighborhood)==arr)\n",
    "    # local_min is a mask that contains the peaks we are \n",
    "    # looking for, but also the background.\n",
    "    # In order to isolate the peaks we must remove the background from the mask.\n",
    "    # \n",
    "    # we create the mask of the background\n",
    "    background = (arr==0)\n",
    "    # \n",
    "    # a little technicality: we must erode the background in order to \n",
    "    # successfully subtract it from local_min, otherwise a line will \n",
    "    # appear along the background border (artifact of the local minimum filter)\n",
    "    # http://www.scipy.org/doc/api_docs/SciPy.ndimage.morphology.html#binary_erosion\n",
    "    eroded_background = morphology.binary_erosion(\n",
    "        background, structure=neighborhood, border_value=1)\n",
    "    # \n",
    "    # we obtain the final mask, containing only peaks, \n",
    "    # by removing the background from the local_min mask\n",
    "    detected_maxima = local_max ^ eroded_background\n",
    "    return np.where(detected_maxima) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_potentials():\n",
    "    global dest\n",
    "    TotPot = np.zeros((Nx,Ny))\n",
    "    TotPot =- np.sqrt((dest[0]-x[:,None])**2+(dest[1]-y[None,:])**2)\n",
    "    TotPot += 0.003*TrailPotential\n",
    "    maxima=detect_local_maxima(TotPot)\n",
    "    cs = plt.contourf(X, Y, TotPot, levels=np.linspace(TotPot.min(),TotPot.max(),1000),cmap='PuBu_r')\n",
    "    cbar = plt.colorbar()\n",
    "    print(maxima)\n",
    "    plt.scatter(x[maxima[0]],y[maxima[1]])\n",
    "    plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1],1)\n",
    "    plt.show\n",
    "    # commit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rowval = np.empty((1,Ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "iterations = 100\n",
    "walkersperiteration = int(len(route))\n",
    "plotfrequency = 1 # number of plots you want (including final), make sure 'iterations' is divisible by this\n",
    "plotevery = iterations/plotfrequency\n",
    "stalledpos = []\n",
    "walker_times = []\n",
    "iteration_times = []\n",
    "calc_tr_times = []\n",
    "comparison_factor_array = []\n",
    "stalledpos_stop_threshold = 1.1\n",
    "endmainloop = 0\n",
    "intensmaxvals = []\n",
    "#convergence_threshold = ???\n",
    "\n",
    "t11a = time.perf_counter()\n",
    "for i in range(iterations):\n",
    "        t11 = time.perf_counter()\n",
    "\n",
    "        tpot_n_minus_1 = copy.deepcopy(TrailPotential)\n",
    "\n",
    "        calc_tr_new() # original method\n",
    "\n",
    "        #if __name__ == '__main__': # runs parallelised calc_tr --------------pixel method\n",
    "        #    with Pool(processes = multiprocessing.cpu_count()) as pool:\n",
    "        #        starmapargs = [] # container for starmap arguments\n",
    "        #        for xi in range(0,Nx): \n",
    "        #            for yi in range(0,Ny):\n",
    "        #                starmapargs.append((xi,yi,TrailPotential,expdist,z,Weight,Nx,Ny))\n",
    "        #        results3 = pool.starmap(mpf3.calc_tr, starmapargs)\n",
    "        #        for pixel in list(results3):\n",
    "        #            xitemp = pixel[0]\n",
    "        #            yitemp = pixel[1]\n",
    "        #            valuetemp = pixel[2]\n",
    "        #            TrailPotential[xitemp,yitemp] = valuetemp\n",
    "\n",
    "        #if __name__ == '__main__': # runs parallelised calc_tr ------------row method\n",
    "        #    with Pool(processes = multiprocessing.cpu_count()) as pool:\n",
    "        #        starmapargs = [] # container for starmap arguments\n",
    "        #        for xi in range(0,Nx):\n",
    "        #                starmapargs.append((xi,TrailPotential,expdist,z,Weight,Nx,Ny))\n",
    "        #        print('hello 1')\n",
    "        #        results3 = pool.starmap(mpf3_2.calc_tr, starmapargs)\n",
    "        #        print('hello 2')\n",
    "        #        for row in list(results3):\n",
    "        #            xitemp = row[0]\n",
    "        #            valuetemp = row[1]\n",
    "        #            TrailPotential[xitemp] = valuetemp\n",
    "\n",
    "        #if __name__ == '__main__': # runs parallelised calc_tr OLD\n",
    "        #    with Pool(processes = multiprocessing.cpu_count()) as pool:\n",
    "        #        starmapargs = [] # container for starmap arguments\n",
    "        #        for core in range(1,multiprocessing.cpu_count()+1):\n",
    "        #            starmapargs.append((core, TrailPotential, z, Weight, subexpdist)) # list of lists of args\n",
    "        #        TrailPotential[:,:] = 0\n",
    "        #        results = pool.starmap(mpf.calc_tr_new_mp, starmapargs)\n",
    "        #        TrailPotential = np.concatenate(np.array(results[0:4]))\n",
    "                #for ll in results:\n",
    "                #    TrailPotential += np.array(ll)\n",
    "                #Trailpotential = results\n",
    "                #for core in results:\n",
    "\n",
    "                #pool.close()\n",
    "                #pool.join()\n",
    "        \n",
    "        tp_comparison_factor = np.mean(np.subtract(TrailPotential,tpot_n_minus_1))\n",
    "        #if tp_comparison_factor > convergence_threshold: break\n",
    "        print(tp_comparison_factor)\n",
    "        comparison_factor_array.append(tp_comparison_factor)\n",
    "\n",
    "        t22 = time.perf_counter()\n",
    "        print(t22-t11,' = Time taken for calc_tr')\n",
    "        calc_tr_times.append(t22-t11)\n",
    "\n",
    "        intens[:]=0.\n",
    "        stalledpos_tempcounter = 0\n",
    "\n",
    "        if __name__ == '__main__': # runs parallelised set_up_walker\n",
    "            with Pool(processes = multiprocessing.cpu_count()) as pool2:\n",
    "                starmapargs2 = []\n",
    "                for j in range(walkersperiteration):\n",
    "                    #randomroute = np.random.randint(0,len(route))\n",
    "                    #starmapargs2.append((randomroute, route, intens, xmin, xmax, ymin, ymax, Nx, Ny, x, y, TrailPotential)) #random route\n",
    "                    starmapargs2.append((j, route, intens, xmin, xmax, ymin, ymax, Nx, Ny, x, y, TrailPotential))\n",
    "                t11b = time.perf_counter()\n",
    "                results2 = pool2.starmap(mpf7.set_up_walker_mp, starmapargs2)\n",
    "                t22b = time.perf_counter()\n",
    "                print(t22b-t11b,' = Time taken for iteration ', i,)\n",
    "                iteration_times.append(t22b-t11b)\n",
    "                for walker in list(results2):\n",
    "                    print(i, walker[7], '|  Start: ', walker[0], 'Dest: ', walker[1], 'Pos: ', walker[2], 'Time of completion:', walker[8], 'Time taken: ', walker[9])\n",
    "                    track = walker[3] # only keeping last walker's track data, for now\n",
    "\n",
    "                    # experimental\n",
    "                    if walker[7] == 'Reached Goal':\n",
    "                        intens += walker[4] # summing intens from all (successful) walkers\n",
    "\n",
    "                    #intens += walker[4] # summing intens from all walkers\n",
    "\n",
    "                    grad = walker[6] # not sure if this should be last walker or sum of all NOTE: should probably be just the last one\n",
    "                    walker_times.append(float(walker[9])) # collect times taken by walkers to go from A to B\n",
    "                    # if there is a stall, append the coords to a list, count number of stalls in iteration\n",
    "                    if len(walker[5]) != 0:\n",
    "                        stalledpos.append(walker[5])\n",
    "                        stalledpos_tempcounter +=1\n",
    "                    # if number of stalls per iteration is too large, force stop main loop\n",
    "                if stalledpos_tempcounter/walkersperiteration >= stalledpos_stop_threshold:\n",
    "                    print('!!!!  Stopping early; number of stalls > threshold  !!!!')\n",
    "                    endmainloop = 1\n",
    "\n",
    "                finaliteration = i\n",
    "                # collect relevant information from walkers\n",
    "                \n",
    "                intensmaxvals.append(np.max(intens)) # grab max value of intens, possibly for debugging/ sanity check\n",
    "\n",
    "        t11c = time.perf_counter()\n",
    "        update_ground()\n",
    "        t22c = time.perf_counter()\n",
    "        print(t22c-t11c,' = Time taken for update_ground ')\n",
    "        #plot_path() \n",
    "        if (i+1) % plotevery == 0 and i != 0: plot_path()     \n",
    "        #for j in range(0,walkersperiteration):\n",
    "            #set_up_walker(np.random.randint(0,len(route))) # used if you want random routes\n",
    "            #set_up_walker(j) # used if you want to run every route per potential calculation/ iteration\n",
    "            #setup_potentials()\n",
    "            #calc_path()\n",
    "            #now = datetime.now() # referenced elsewhere\n",
    "            #current_time = now.strftime(\"%H:%M:%S\")\n",
    "            #print(i, start,\" -> \", dest, pos,\"      time = \", current_time)\n",
    "        #update_ground()\n",
    "        if endmainloop == 1: break\n",
    "        #plot_path()\n",
    "#print(str(\"Number of walkers = \")+str(numberofwalkers))\n",
    "#print(str('Walker success rate = ')+str(successrate)+str(' %'))\n",
    "#print('Average time taken for walker = '+str(np.mean(walker_times))+ ',    Min = '+str(min(walker_times))+',    Max = '+str(max(walker_times)))\n",
    "#print('Average time taken for calc_tr = '+str(np.mean(calc_tr_times))+ ',    Min = '+str(min(calc_tr_times))+',    Max = '+str(max(calc_tr_times)))\n",
    "t22a = time.perf_counter()\n",
    "print(t22a-t11a, ' = Time taken for whole loop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut (ignore this comment, its for CTRL+F purposes)\n",
    "plot_path()\n",
    "\n",
    "cs = plt.contourf(X, Y, TrailPotential, levels=np.linspace(TrailPotential.min(),TrailPotential.max(),1000),cmap='PuBu_r')\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "z_copy = copy.deepcopy(z)\n",
    "\n",
    "#for i in range (len(z[0])):\n",
    "#    for j in range (len(z)):\n",
    "#        if z[i][j] >= 199:\n",
    "#            z_copy[i][j] = 180\n",
    "#        elif 150 <= z[i][j] < 199:\n",
    "#            z_copy[i][j] = 90\n",
    "#        else:\n",
    "#            z_copy[i][j] = 0\n",
    "\n",
    "def plot_path_threshold():\n",
    "    plt.contourf(X, Y, z, levels=np.linspace(-20,180,100),cmap='terrain')\n",
    "    plt.colorbar()\n",
    "    #plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1],1)\n",
    "    plt.show(block=False)\n",
    "\n",
    "plot_path_threshold()\n",
    "\n",
    "numberofwalkers = (finaliteration+1)*walkersperiteration\n",
    "successrate = 100-(100*len(stalledpos))/numberofwalkers\n",
    "\n",
    "print('isigma = ',isigma)\n",
    "print('trailpotweight = ','0.004')\n",
    "print('trailpotweight (after stall) = ','0.002')\n",
    "print('t_track =',t_track)\n",
    "\n",
    "#print(str(\"Number of walkers = \")+str(finaliteration*walkersperiteration+stalledpos_stop_threshold*walkersperiteration))\n",
    "print(\"Number of walkers = \",walkersperiteration*(finaliteration+1))\n",
    "print(\"Number of iterations = \",finaliteration+1)\n",
    "print('Walkers per iteration = ',walkersperiteration)\n",
    "\n",
    "\n",
    "\n",
    "print(str('Walker success rate = ')+str(successrate)+str(' %'))\n",
    "print('Average time taken per walker = '+str(np.mean(walker_times))+ ',    Min = '+str(min(walker_times))+',    Max = '+str(max(walker_times)))\n",
    "print('Average time taken per iteration = '+str(np.mean(iteration_times))+ ',    Min = '+str(min(iteration_times))+',    Max = '+str(max(iteration_times)))\n",
    "print('Average time taken for calc_tr = '+str(np.mean(calc_tr_times))+ ',    Min = '+str(min(calc_tr_times))+',    Max = '+str(max(calc_tr_times)))\n",
    "print('Time taken for whole loop = ',t22a-t11a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([walker_times], labels=['Walker times'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([iteration_times], labels=[\"Iteration times\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([calc_tr_times], labels=[\"'Calc_tr' times\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(comparison_factor_array)\n",
    "print(comparison_factor_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(calc_tr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(walker_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,Nx):\n",
    "    for j in range(0,Ny):\n",
    "        if (np.isnan(z[i,j])):\n",
    "            print (i,j,g_max[i,j],Base[i,j,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,Nx):\n",
    "    for j in range(0,Ny):\n",
    "        if (np.isnan(z[i,j])):\n",
    "            print (i,j,g_max[i,j],Base[i,j,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_potentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrailPotential = sg.convolve2d(z*Weight,subexpdist[:,:],mode=\"same\")\n",
    "#print(TrailPotential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the direction\n",
    "scgrad=np.arctan2(grad[1],grad[0])\n",
    "levels = np.linspace(-np.pi, np.pi, 360)\n",
    "cs = plt.contourf(X, Y,scgrad, levels=levels,cmap='hsv')\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "#plt.scatter(track[0:wlkr_range-1,0],track[0:wlkr_range-1,1])\n",
    "#plt.scatter(start, dest)\n",
    "print(start)\n",
    "print(dest)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrate z, trapezoid rule eq 20\n",
    "# def calc_tr():\n",
    "#    global xi,yi,TrailPotential,expdist,z,Weight,Nx,Ny\n",
    "#    for xi in range(0,Nx): \n",
    "#        for yi in range(0,Ny):\n",
    "#            TrailPotential[xi,yi]=np.sum(expdist[Nx-1-xi:2*Nx-1-xi,Ny-1-yi:2*Ny-1-yi]*z[:,:]*Weight[:,:])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
